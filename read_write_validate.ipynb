{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.162:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ReadWriteVal</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1105da898>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ReadWriteVal\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many cores you have\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/\"\n",
    "\n",
    "students = spark.read.csv(path+'students.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|       lunch|test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "|female|       group B|          bachelor's degree|    standard|                   none|        72|           72|           74|\n",
      "|female|       group C|               some college|    standard|              completed|        69|           90|           88|\n",
      "|female|       group B|            master's degree|    standard|                   none|        90|           95|           93|\n",
      "|  male|       group A|         associate's degree|free/reduced|                   none|        47|           57|           44|\n",
      "|  male|       group C|               some college|    standard|                   none|        76|           78|           75|\n",
      "+------+--------------+---------------------------+------------+-----------------------+----------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.parquet(path+'users1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+----------+---------+--------------------+------+--------------+----------------+---------+---------+---------+--------------------+--------+\n",
      "|  registration_dttm| id|first_name|last_name|               email|gender|    ip_address|              cc|  country|birthdate|   salary|               title|comments|\n",
      "+-------------------+---+----------+---------+--------------------+------+--------------+----------------+---------+---------+---------+--------------------+--------+\n",
      "|2016-02-03 05:55:29|  1|    Amanda|   Jordan|    ajordan0@com.com|Female|   1.197.201.2|6759521864920116|Indonesia| 3/8/1971| 49756.53|    Internal Auditor|   1E+02|\n",
      "|2016-02-03 15:04:03|  2|    Albert|  Freeman|     afreeman1@is.gd|  Male|218.111.175.34|                |   Canada|1/16/1968|150280.17|       Accountant IV|        |\n",
      "|2016-02-02 23:09:31|  3|    Evelyn|   Morgan|emorgan2@altervis...|Female|  7.161.136.94|6767119071901597|   Russia| 2/1/1960|144972.51| Structural Engineer|        |\n",
      "|2016-02-02 22:36:21|  4|    Denise|    Riley|    driley3@gmpg.org|Female| 140.35.109.83|3576031598965625|    China| 4/8/1997| 90263.05|Senior Cost Accou...|        |\n",
      "+-------------------+---+----------+---------+--------------------+------+--------------+----------------+---------+---------+---------+--------------------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = spark.read.parquet(path+'users*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+----------+---------+--------------------+------+--------------+----------------+---------+---------+---------+--------------------+--------+\n",
      "|  registration_dttm| id|first_name|last_name|               email|gender|    ip_address|              cc|  country|birthdate|   salary|               title|comments|\n",
      "+-------------------+---+----------+---------+--------------------+------+--------------+----------------+---------+---------+---------+--------------------+--------+\n",
      "|2016-02-03 05:55:29|  1|    Amanda|   Jordan|    ajordan0@com.com|Female|   1.197.201.2|6759521864920116|Indonesia| 3/8/1971| 49756.53|    Internal Auditor|   1E+02|\n",
      "|2016-02-03 15:04:03|  2|    Albert|  Freeman|     afreeman1@is.gd|  Male|218.111.175.34|                |   Canada|1/16/1968|150280.17|       Accountant IV|        |\n",
      "|2016-02-02 23:09:31|  3|    Evelyn|   Morgan|emorgan2@altervis...|Female|  7.161.136.94|6767119071901597|   Russia| 2/1/1960|144972.51| Structural Engineer|        |\n",
      "|2016-02-02 22:36:21|  4|    Denise|    Riley|    driley3@gmpg.org|Female| 140.35.109.83|3576031598965625|    China| 4/8/1997| 90263.05|Senior Cost Accou...|        |\n",
      "+-------------------+---+----------+---------+--------------------+------+--------------+----------------+---------+---------+---------+--------------------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partitions.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_1_2 = spark.read.parquet(path+'users1.parquet', path+'users2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: string (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: integer (nullable = true)\n",
      " |-- reading score: integer (nullable = true)\n",
      " |-- writing score: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'race/ethnicity',\n",
       " 'parental level of education',\n",
       " 'lunch',\n",
       " 'test preparation course',\n",
       " 'math score',\n",
       " 'reading score',\n",
       " 'writing score']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, gender: string, race/ethnicity: string, parental level of education: string, lunch: string, test preparation course: string, math score: string, reading score: string, writing score: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntegerType"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.schema['math score'].dataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+\n",
      "|summary|math score|reading score|\n",
      "+-------+----------+-------------+\n",
      "|  count|      1000|         1000|\n",
      "|    min|         0|           17|\n",
      "|    max|       100|          100|\n",
      "+-------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students.select(\"math score\", \"reading score\").summary(\"count\", \"min\", \"max\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to specify data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField('name', StringType(), True),\n",
    "              StructField('email', StringType(), True),\n",
    "              StructField('city', StringType(), True),\n",
    "              StructField('mac', StringType(), True),\n",
    "              StructField('timestamp', DateType(), True),\n",
    "              StructField('creditcard', StringType(), True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_struc = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = spark.read.json(path+'people.json', schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+-----------------+----------+-------------------+\n",
      "|                name|               email|           city|              mac| timestamp|         creditcard|\n",
      "+--------------------+--------------------+---------------+-----------------+----------+-------------------+\n",
      "|                null|                null|           null|             null|      null|               null|\n",
      "|        Keeley Bosco|katlyn@jenkinsmag...|Lake Gladysberg|08:fd:0b:cd:77:f7|2015-04-25|1228-1221-1221-1431|\n",
      "|         Rubye Jerde|juvenal@johnston....|           null|90:4d:fa:42:63:a2|2015-04-25|1228-1221-1221-1431|\n",
      "|Miss Darian Breit...|                null|           null|f9:0e:d3:40:cb:e9|2015-04-25|               null|\n",
      "+--------------------+--------------------+---------------+-----------------+----------+-------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
